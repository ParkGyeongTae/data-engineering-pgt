import pandas as pd
import requests
import yfinance as yf
from bs4 import BeautifulSoup


# âœ… S&P500 ì¢…ëª© ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (Wikipedia)
def get_sp500_tickers():
    url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")
    table = soup.find("table")
    df = pd.read_html(str(table))[0]
    return df["Symbol"].tolist()


# âœ… ì‹œê°€ì´ì•¡ ê³„ì‚° í•¨ìˆ˜
def get_today_top_sp500(n=10):
    tickers = get_sp500_tickers()
    data = []

    for ticker in tickers:
        try:
            info = yf.Ticker(ticker).info
            name = info.get("shortName", ticker)
            mcap = info.get("marketCap", 0)
            data.append(
                {
                    "í‹°ì»¤": ticker,
                    "ì¢…ëª©ëª…": name,
                    "ì‹œê°€ì´ì•¡(ì–µë‹¬ëŸ¬)": round(mcap / 1e8, 1),
                }
            )
        except Exception:
            continue

    df = pd.DataFrame(data)
    df = (
        df.sort_values("ì‹œê°€ì´ì•¡(ì–µë‹¬ëŸ¬)", ascending=False)
        .head(n)
        .reset_index(drop=True)
    )
    df.insert(0, "ìˆœìœ„", df.index + 1)
    return df


# âœ… ì‹¤í–‰
if __name__ == "__main__":
    top10 = get_today_top_sp500(10)
    pd.set_option("display.max_rows", 20)
    print("\nğŸ“ˆ ì˜¤ëŠ˜ ê¸°ì¤€ S&P500 ì‹œê°€ì´ì•¡ ìƒìœ„ 10ê°œ")
    print(top10.to_string(index=False))
